{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNCF-pytorch demo (CIFAR-10/resnet-18)",
      "provenance": [],
      "collapsed_sections": [
        "K5HPrY_d-7cV",
        "E01dMaR2_AFL",
        "qMnYsGo9_MA8",
        "L0tH9KdwtHhV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "git68adWeq4l"
      },
      "source": [
        "#Intro\r\n",
        "\r\n",
        "This notebook is based on 'ImageNet training in PyTorch' [example](https://github.com/pytorch/examples/blob/master/imagenet/main.py).\r\n",
        "\r\n",
        "The goal of this notebook is not to reach the best possible baselines for the implemented compression algorithms, but to demonstrate simple use cases of [NNCF](https://github.com/openvinotoolkit/nncf) with Pytorch. For more advanced usage refer to these [examples](https://github.com/openvinotoolkit/nncf/tree/develop/examples).\r\n",
        "\r\n",
        "To make the demonstration easier and faster, we propose to use ResNet-18 model with CIFAR-10 dataset. But it is possible to change it.\r\n",
        "\r\n",
        "Demonstrated algorithms:\r\n",
        "\r\n",
        "- [Quantization](https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Quantization.md)\r\n",
        "\r\n",
        "TODO:\r\n",
        "- [Filter pruning](https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Pruning.md)\r\n",
        "\r\n",
        "- [Sparsity](https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Sparsity.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M1xndNu-z_2"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIo5S145S0Ug"
      },
      "source": [
        "!pip install nncf==1.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwY9bxvth56S"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import nncf  # Important - should be imported directly after torch\n",
        "from nncf import create_compressed_model, NNCFConfig, register_default_init_args\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4H9sI_uJOrT"
      },
      "source": [
        "Connect to google drive to save and get access to the pretrained model (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q58vQSLWIwBp",
        "outputId": "711fd5ac-48a1-4cec-8a7a-02b7ec05403a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZX2GAh3W7ZT"
      },
      "source": [
        "# path to the saved model checkpoint, can be any\r\n",
        "# PATH = ''\r\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/nncf/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5HPrY_d-7cV"
      },
      "source": [
        "#Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLEwoilKiQYk"
      },
      "source": [
        "def main(params):\n",
        "\n",
        "    arch = params['arch']\n",
        "    num_classes = params['num_classes']\n",
        "    input_size = params['input_size']\n",
        "\n",
        "    optimizer_type = params['optimizer_type'] = 'SGD'\n",
        "    init_lr = params['init_lr']\n",
        "    adjustable_lr = params['adjustable_lr']\n",
        "    momentum = params['momentum']\n",
        "    weight_decay = params['weight_decay']\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    workers = params['workers']\n",
        "    pretrained = params['pretrained']\n",
        "    resume = params['resume']\n",
        "    checkpoint_compressed = params['checkpoint_compressed']\n",
        "    evaluate = params['evaluate']\n",
        "    start_epoch = params['start_epoch']\n",
        "    epochs = params['epochs']\n",
        "\n",
        "    use_nncf = params['use_nncf']\n",
        "    if use_nncf:\n",
        "        nncf_config_file = params['nncf_config_file']\n",
        "        epochs_tune = params['epochs_tune']\n",
        "\n",
        "    best_acc1 = 0\n",
        "\n",
        "    # create model\n",
        "    if pretrained:\n",
        "        print(\"=> using pre-trained model '{}'\".format(arch))\n",
        "        model = models.__dict__[arch](pretrained=True)\n",
        "    else:\n",
        "        print(\"=> creating model '{}'\".format(arch))\n",
        "        model = models.__dict__[arch]()\n",
        "    # update the last FC layer for tiny-imagenet number of classes\n",
        "    model.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
        "\n",
        "    # define loss function (criterion)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print('using CPU, this will be slow')\n",
        "    else:\n",
        "        print('using GPU')\n",
        "        model.cuda()\n",
        "        model.fc = model.fc.cuda()\n",
        "        criterion.cuda()\n",
        "\n",
        "    # define optimizer\n",
        "    if optimizer_type == 'SGD':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=init_lr,\n",
        "                              momentum=momentum, weight_decay=weight_decay)\n",
        "    elif optimizer_type == 'Adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
        "    else:\n",
        "        print('Support only SGD and Adam optimizers')\n",
        "        return\n",
        "    if adjustable_lr:\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "    # optionally: resume from a checkpoint\n",
        "    if resume:\n",
        "        if os.path.isfile(resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
        "            #\n",
        "            # ** WARNING: torch.load functionality uses Python's pickling facilities that\n",
        "            # may be used to perform arbitrary code execution during unpickling. Only load the data you\n",
        "            # trust.\n",
        "            #\n",
        "            checkpoint = torch.load(resume)\n",
        "\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            print('resumed start_epoch', start_epoch)\n",
        "            best_acc1 = checkpoint['best_acc1']\n",
        "\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {}, best_acc1 {:6.2f})\"\n",
        "                  .format(resume, checkpoint['epoch'], checkpoint['best_acc1']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
        "\n",
        "    # Data\n",
        "    print('==> Preparing data..')\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=100, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "    #           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "    if use_nncf:\n",
        "        # Load a configuration file to specify compression\n",
        "        nncf_config = NNCFConfig.from_json(nncf_config_file)\n",
        "        # Provide data loaders for compression algorithm initialization, if necessary\n",
        "        nncf_config = register_default_init_args(nncf_config, train_loader, criterion)\n",
        "        # Apply the specified compression algorithms to the model\n",
        "        print('=> compressing the model with {}'.format(nncf_config_file))\n",
        "        compression_ctrl, model = create_compressed_model(model, nncf_config)\n",
        "\n",
        "        epochs = start_epoch + epochs_tune\n",
        "\n",
        "    if evaluate:\n",
        "        validate(val_loader, model, criterion)\n",
        "        return\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        adjust_learning_rate(optimizer, epoch, init_lr)\n",
        "\n",
        "        if use_nncf:\n",
        "            # update compression scheduler state at the begin of the epoch\n",
        "            compression_ctrl.scheduler.epoch_step()\n",
        "            # tune for one epoch with nncf\n",
        "            train(train_loader, model, criterion, optimizer, epoch, use_nncf, compression_ctrl=compression_ctrl)\n",
        "        else:\n",
        "            # train for one epoch without nncf\n",
        "            train(train_loader, model, criterion, optimizer, epoch, use_nncf, compression_ctrl=None)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        acc1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        if adjustable_lr:\n",
        "            scheduler.step()\n",
        "\n",
        "        # remember best acc@1 and save checkpoint\n",
        "        is_best = acc1 > best_acc1\n",
        "        best_acc1 = max(acc1, best_acc1)\n",
        "\n",
        "        if not use_nncf:\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'arch': arch,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_acc1': best_acc1,\n",
        "                'optimizer' : optimizer.state_dict(),\n",
        "            }, is_best, batch_size, input_size)\n",
        "    \n",
        "    # Export the compressed model to ONNX format that is supported by the OpenVINO™ toolkit\n",
        "    if use_nncf:\n",
        "        compression_ctrl.export_model(PATH + \"best_model_compressed.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E01dMaR2_AFL"
      },
      "source": [
        "#Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940rcAIyiXml"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch, use_nncf, compression_ctrl):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    data_time = AverageMeter('Data', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(train_loader),\n",
        "        [batch_time, data_time, losses, top1, top5],\n",
        "        prefix=\"Epoch: [{}]\".format(epoch))\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_nncf:\n",
        "            compression_ctrl.scheduler.step()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(images)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        if use_nncf:\n",
        "            compression_loss = compression_ctrl.loss()\n",
        "            loss += compression_loss\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), images.size(0))\n",
        "        top1.update(acc1[0], images.size(0))\n",
        "        top5.update(acc5[0], images.size(0))\n",
        "\n",
        "        # compute gradient and do opt step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        print_frequency = 10\n",
        "        if i % print_frequency == 0:\n",
        "            progress.display(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoNr8qwm_El2"
      },
      "source": [
        "#Validate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgnugrWgicWC"
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(\n",
        "        len(val_loader),\n",
        "        [batch_time, losses, top1, top5],\n",
        "        prefix='Test: ')\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        end = time.time()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            losses.update(loss.item(), images.size(0))\n",
        "            top1.update(acc1[0], images.size(0))\n",
        "            top5.update(acc5[0], images.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            print_frequency = 10\n",
        "            if i % print_frequency == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        # TODO: this should also be done with the ProgressMeter\n",
        "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "              .format(top1=top1, top5=top5))\n",
        "\n",
        "    return top1.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMnYsGo9_MA8"
      },
      "source": [
        "#Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R724tbxcidQE"
      },
      "source": [
        "def save_checkpoint(state, is_best, batch_size, input_size, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, os.path.join(PATH, filename))\n",
        "    if is_best:\n",
        "        shutil.copyfile(os.path.join(PATH, filename), os.path.join(PATH, 'model_best.pth.tar'))\n",
        "        # Save in ONNX format\n",
        "        x = torch.randn(batch_size, 3, input_size, input_size)\n",
        "        torch.onnx.export(model, x, PATH + \"model_best.onnx\")\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def display(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcSjyLBwiqBx"
      },
      "source": [
        "def adjust_learning_rate(optimizer, epoch, init_lr):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = init_lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118rlV22_PB5"
      },
      "source": [
        "#Main\r\n",
        "\r\n",
        "Pipeline:\r\n",
        "\r\n",
        "- Train without NNCF, save best checkpoint in float precision\r\n",
        "\r\n",
        "- Load best float checkpoint and compress it with selected algorithm (convert the model to NNCFNetwork format by enabling NNCF) TODO: be able to load the compressed model for further tuning\r\n",
        "\r\n",
        "- Tune the compressed model (train with enabled NNCF, define the tune parameters in the corresponding configuraion files)\r\n",
        "\r\n",
        "- Save compressed tuned model (or convert to ONNX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0tH9KdwtHhV"
      },
      "source": [
        "## Configuration files for compression algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaf3cjgSyQh5"
      },
      "source": [
        "def create_json_files(batch_size, input_size):\r\n",
        "    \"\"\"\r\n",
        "    Define configurations for compression algorithms\r\n",
        "    Create the json files\r\n",
        "    Return the configurations as dictinary objects\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    config_dir = 'config_files'\r\n",
        "    if not os.path.exists(config_dir):\r\n",
        "        os.makedirs(config_dir)\r\n",
        "\r\n",
        "    def write_json(json_obj, json_name):\r\n",
        "        with open(os.path.join(config_dir, json_name), 'w') as jsonFile:\r\n",
        "            json.dump(json_obj, jsonFile)\r\n",
        "\r\n",
        "    # Define config objects below\r\n",
        "    configs = {}\r\n",
        "\r\n",
        "    # Quantization int8\r\n",
        "    # https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Quantization.md\r\n",
        "    configs['quantization.json'] = {\r\n",
        "\r\n",
        "            \"input_info\": {\r\n",
        "              \"sample_size\": [batch_size, 3, input_size, input_size]\r\n",
        "            },\r\n",
        "\r\n",
        "            \"epochs\": 1, # number of epochs to tune\r\n",
        "\r\n",
        "            \"optimizer\": { # optimizer used during tuning\r\n",
        "                \"type\": \"Adam\",\r\n",
        "                \"base_lr\": 1e-5\r\n",
        "            },\r\n",
        "\r\n",
        "            \"compression\": {\r\n",
        "                    \"algorithm\": \"quantization\", # specify the algorithm here\r\n",
        "            }\r\n",
        "    }\r\n",
        "\r\n",
        "    # create json files, that will be used by nncf later\r\n",
        "    for config_key, config_val in configs.items():\r\n",
        "        write_json(config_val, config_key)\r\n",
        "    \r\n",
        "    return configs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d8LOmKut36x"
      },
      "source": [
        "## Train/tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk0Nub3KiqZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17396a4-db19-43c8-cfcd-31b4c2a9ce2b"
      },
      "source": [
        "params = {}\n",
        "\n",
        "params['arch'] = 'resnet18'\n",
        "params['num_classes'] = 10 # For Cifar10\n",
        "params['input_size'] = 224\n",
        "\n",
        "params['optimizer_type'] = 'SGD' # \"Adam\"\n",
        "params['init_lr'] = 0.1\n",
        "params['momentum'] = 0.9\n",
        "params['weight_decay'] = 5e-4\n",
        "params['adjustable_lr'] = True\n",
        "params['batch_size'] = 128\n",
        "params['workers'] = 4\n",
        "params['start_epoch'] = 0 # updated automatically if training is resumed\n",
        "params['epochs'] = 100 # for full precision training, will be updated (increased) in case of tuning with nncf \n",
        "params['pretrained'] = True # pretrained model on Imagenet\n",
        "\n",
        "params['resume'] = PATH + 'model_best.pth.tar'  # path to latest checkpoint (or None)\n",
        "params['checkpoint_compressed'] = False\n",
        "\n",
        "params['evaluate'] = False # test on the validation set and exit\n",
        "\n",
        "params['use_nncf'] = True # enable model compression and tuning\n",
        "\n",
        "params['nncf_config_file'] = None\n",
        "if params['use_nncf']:\n",
        "    # create all config files\n",
        "    configs = create_json_files(params['batch_size'], params['input_size'])\n",
        "\n",
        "    # choose config file\n",
        "    algorithm_config = 'quantization.json'\n",
        "    params['nncf_config_file'] = 'config_files/' + algorithm_config\n",
        "\n",
        "    # update tune params to fit certain compression algorithm\n",
        "    params['optimizer_type'] = configs[algorithm_config]['optimizer']['type']\n",
        "    params['init_lr'] = configs[algorithm_config]['optimizer']['base_lr']\n",
        "    params['adjustable_lr'] = False\n",
        "    # params['epochs'] = params['epochs'] + configs[algorithm_config]['epochs']\n",
        "    params['epochs_tune'] = configs[algorithm_config]['epochs']\n",
        "\n",
        "\n",
        "# Run certain algorithm once\n",
        "main(params)\n",
        "\n",
        "# Iterate over algorithms\n",
        "# TODO: add more algorithms\n",
        "algorithm_configs = ['quantization.json']\n",
        "for algorithm_config in algorithm_configs:\n",
        "    # Run the tuning procedure:\n",
        "    # print(algorithm_config)\n",
        "    # params['nncf_config_file'] = 'config_files/' + algorithm_config\n",
        "    # update tune params\n",
        "    # main(params)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> using pre-trained model 'resnet18'\n",
            "using GPU\n",
            "=> loading checkpoint '/content/drive/MyDrive/Colab Notebooks/nncf/model_best.pth.tar'\n",
            "resumed start_epoch 49\n",
            "=> loaded checkpoint '/content/drive/MyDrive/Colab Notebooks/nncf/model_best.pth.tar' (epoch 49, best_acc1  91.33)\n",
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "=> compressing the model with config_files/quantization.json\n",
            "WARNING:nncf:Graphviz is not installed - only the .dot model visualization format will be used. Install pygraphviz into your Python environment and graphviz system-wide to enable PNG rendering.\n",
            "INFO:nncf:Wrapping module ResNet/Conv2d[conv1] by ResNet/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1] by ResNet/Sequential[layer1]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2] by ResNet/Sequential[layer1]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1] by ResNet/Sequential[layer1]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2] by ResNet/Sequential[layer1]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1] by ResNet/Sequential[layer2]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2] by ResNet/Sequential[layer2]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1] by ResNet/Sequential[layer2]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2] by ResNet/Sequential[layer2]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1] by ResNet/Sequential[layer3]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2] by ResNet/Sequential[layer3]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1] by ResNet/Sequential[layer3]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2] by ResNet/Sequential[layer3]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1] by ResNet/Sequential[layer4]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2] by ResNet/Sequential[layer4]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1] by ResNet/Sequential[layer4]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2] by ResNet/Sequential[layer4]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Wrapping module ResNet/Linear[fc] by ResNet/NNCFLinear[fc]\n",
            "INFO:nncf:Creating compression algorithm: quantization\n",
            "WARNING:nncf:Enabling quantization range initialization with default parameters.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nncf/hw_config.py:200: UserWarning: Operation name Crop in HW config is not registered in NNCF under any supported operation metatype - will be ignored\n",
            "  \"metatype - will be ignored\".format(hw_config_op_name))\n",
            "/usr/local/lib/python3.6/dist-packages/nncf/hw_config.py:200: UserWarning: Operation name StridedSlice in HW config is not registered in NNCF under any supported operation metatype - will be ignored\n",
            "  \"metatype - will be ignored\".format(hw_config_op_name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:nncf:Algorithm initialization ████████          | 1 / 2\n",
            "INFO:nncf:Algorithm initialization ████████████████  | 2 / 2\n",
            "INFO:nncf:Set sign: False and scale: [8.2491, ] for ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [3.4222, ] for ResNet/AdaptiveAvgPool2d[avgpool]/adaptive_avg_pool2d_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/AdaptiveAvgPool2d[avgpool]/adaptive_avg_pool2d_0\n",
            "INFO:nncf:Set sign: True and scale: [2.7537, ] for /nncf_model_input_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: /nncf_model_input_0\n",
            "INFO:nncf:Set sign: False and scale: [0.9314, ] for ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [0.8328, ] for ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [2.1759, ] for ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [2.9128, ] for ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [2.3370, ] for ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [3.7008, ] for ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: True and scale: [2.5109, ] for ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [1.7244, ] for ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [2.9813, ] for ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [2.1730, ] for ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [2.4216, ] for ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: True and scale: [2.8622, ] for ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [1.5621, ] for ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [2.2969, ] for ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [2.2499, ] for ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [2.7403, ] for ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: True and scale: [1.8709, ] for ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [2.5319, ] for ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: True and scale: [8.1179, ] for ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Adding signed Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]/batch_norm_0\n",
            "INFO:nncf:Set sign: False and scale: [4.2225, ] for ResNet/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/ReLU[relu]/RELU_0\n",
            "INFO:nncf:Set sign: False and scale: [3.8168, ] for ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [4.0575, ] for ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [3.8942, ] for ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [4.5681, ] for ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [2.8837, ] for ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [3.4440, ] for ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: False and scale: [2.6902, ] for ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Adding unsigned Activation Quantize in scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/RELU_1\n",
            "INFO:nncf:Set sign: True and scale: [0.1450, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/64 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/64 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer1]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/64 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer1]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1070, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/64 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer1]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/64 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer1]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1036, 0.1207, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/128 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer2]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1611, 0.3747, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/128 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer2]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1478, 0.1000, 0.1000, 0.1159, 0.1000, 0.1000, 0.4004, 0.1000, 0.1000, 0.1000, ... (first 10/128 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Set sign: True and scale: [0.1688, 0.1000, 0.1000, 0.1765, 0.1000, 0.1000, 0.1712, 0.1000, 0.1066, 0.1649, ... (first 10/128 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer2]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.2018, 0.1000, 0.1000, 0.1331, 0.1000, 0.1000, 0.1000, ... (first 10/128 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer2]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1222, 0.1000, 0.1000, ... (first 10/256 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer3]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1306, 0.1000, ... (first 10/256 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer3]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1611, 0.1000, 0.1000, ... (first 10/256 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1029, 0.1000, ... (first 10/256 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer3]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/256 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer3]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1420, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/512 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer4]/BasicBlock[0]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1155, 0.1000, ... (first 10/512 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer4]/BasicBlock[0]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1209, 0.1000, 0.1000, 0.1000, ... (first 10/512 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/NNCFConv2d[0]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/512 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer4]/BasicBlock[1]/NNCFConv2d[conv1]\n",
            "INFO:nncf:Set sign: True and scale: [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, ... (first 10/512 elements shown only) ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/Sequential[layer4]/BasicBlock[1]/NNCFConv2d[conv2]\n",
            "INFO:nncf:Set sign: True and scale: [0.7105, 0.6538, 0.5205, 0.6448, 0.6065, 0.7131, 1.0289, 0.5199, 1.0313, 0.8274, ] for InsertionType.NNCF_MODULE_PRE_OP ResNet/NNCFLinear[fc]\n",
            "WARNING:nncf:Enabling quantization batch norm adaptation with default parameters.\n",
            "INFO:nncf:BatchNorm statistics adaptation █                 | 1 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ██                | 2 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ███               | 3 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ████              | 4 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation █████             | 5 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ██████            | 6 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ███████           | 7 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ████████          | 8 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation █████████         | 9 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ██████████        | 10 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ███████████       | 11 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ████████████      | 12 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation █████████████     | 13 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ██████████████    | 14 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ███████████████   | 15 / 16\n",
            "INFO:nncf:BatchNorm statistics adaptation ████████████████  | 16 / 16\n",
            "WARNING:nncf:Graphviz is not installed - only the .dot model visualization format will be used. Install pygraphviz into your Python environment and graphviz system-wide to enable PNG rendering.\n",
            "Epoch: [49][  0/391]\tTime  0.935 ( 0.935)\tData  0.597 ( 0.597)\tLoss 5.0227e-02 (5.0227e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][ 10/391]\tTime  0.501 ( 0.554)\tData  0.000 ( 0.078)\tLoss 1.4988e-02 (4.6769e-02)\tAcc@1 100.00 ( 98.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][ 20/391]\tTime  0.522 ( 0.536)\tData  0.000 ( 0.056)\tLoss 8.0315e-02 (4.5323e-02)\tAcc@1  96.88 ( 98.74)\tAcc@5  99.22 ( 99.96)\n",
            "Epoch: [49][ 30/391]\tTime  0.508 ( 0.529)\tData  0.000 ( 0.048)\tLoss 5.9971e-02 (4.4740e-02)\tAcc@1  97.66 ( 98.71)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [49][ 40/391]\tTime  0.511 ( 0.525)\tData  0.000 ( 0.044)\tLoss 1.4516e-02 (4.4608e-02)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [49][ 50/391]\tTime  0.489 ( 0.520)\tData  0.000 ( 0.041)\tLoss 7.1407e-02 (4.4279e-02)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [49][ 60/391]\tTime  0.488 ( 0.515)\tData  0.000 ( 0.039)\tLoss 9.6052e-02 (4.3315e-02)\tAcc@1  96.09 ( 98.73)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][ 70/391]\tTime  0.476 ( 0.512)\tData  0.000 ( 0.038)\tLoss 4.6145e-02 (4.1937e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][ 80/391]\tTime  0.489 ( 0.509)\tData  0.000 ( 0.036)\tLoss 1.0582e-01 (4.2698e-02)\tAcc@1  96.88 ( 98.74)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][ 90/391]\tTime  0.482 ( 0.506)\tData  0.000 ( 0.035)\tLoss 4.0472e-02 (4.1917e-02)\tAcc@1  99.22 ( 98.76)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][100/391]\tTime  0.476 ( 0.504)\tData  0.000 ( 0.035)\tLoss 2.9557e-02 (4.1486e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][110/391]\tTime  0.473 ( 0.502)\tData  0.000 ( 0.034)\tLoss 4.1732e-02 (4.2230e-02)\tAcc@1  99.22 ( 98.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][120/391]\tTime  0.480 ( 0.500)\tData  0.000 ( 0.034)\tLoss 4.2927e-02 (4.2526e-02)\tAcc@1  98.44 ( 98.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][130/391]\tTime  0.484 ( 0.499)\tData  0.000 ( 0.033)\tLoss 1.6956e-02 (4.1654e-02)\tAcc@1 100.00 ( 98.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][140/391]\tTime  0.488 ( 0.498)\tData  0.000 ( 0.033)\tLoss 3.5884e-02 (4.2084e-02)\tAcc@1  99.22 ( 98.76)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][150/391]\tTime  0.489 ( 0.498)\tData  0.000 ( 0.032)\tLoss 4.9706e-02 (4.2118e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [49][160/391]\tTime  0.495 ( 0.498)\tData  0.000 ( 0.032)\tLoss 6.8018e-02 (4.2661e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][170/391]\tTime  0.487 ( 0.497)\tData  0.000 ( 0.032)\tLoss 3.2312e-02 (4.2187e-02)\tAcc@1  99.22 ( 98.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][180/391]\tTime  0.488 ( 0.497)\tData  0.000 ( 0.032)\tLoss 4.3629e-02 (4.1978e-02)\tAcc@1  98.44 ( 98.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][190/391]\tTime  0.496 ( 0.497)\tData  0.000 ( 0.032)\tLoss 9.9270e-02 (4.2016e-02)\tAcc@1  97.66 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][200/391]\tTime  0.489 ( 0.497)\tData  0.000 ( 0.032)\tLoss 6.9546e-02 (4.2655e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][210/391]\tTime  0.491 ( 0.497)\tData  0.000 ( 0.031)\tLoss 2.7895e-02 (4.2663e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][220/391]\tTime  0.499 ( 0.497)\tData  0.000 ( 0.031)\tLoss 1.4544e-02 (4.2762e-02)\tAcc@1 100.00 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][230/391]\tTime  0.483 ( 0.497)\tData  0.000 ( 0.031)\tLoss 3.8025e-02 (4.2568e-02)\tAcc@1  97.66 ( 98.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][240/391]\tTime  0.489 ( 0.497)\tData  0.000 ( 0.031)\tLoss 5.6410e-02 (4.2348e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][250/391]\tTime  0.482 ( 0.497)\tData  0.000 ( 0.031)\tLoss 4.1488e-02 (4.1996e-02)\tAcc@1  98.44 ( 98.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][260/391]\tTime  0.482 ( 0.496)\tData  0.000 ( 0.031)\tLoss 2.4558e-02 (4.2286e-02)\tAcc@1  99.22 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][270/391]\tTime  0.494 ( 0.496)\tData  0.000 ( 0.031)\tLoss 5.2694e-02 (4.2658e-02)\tAcc@1  96.88 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][280/391]\tTime  0.487 ( 0.495)\tData  0.000 ( 0.031)\tLoss 3.3863e-02 (4.2659e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][290/391]\tTime  0.487 ( 0.495)\tData  0.000 ( 0.031)\tLoss 3.0907e-02 (4.2396e-02)\tAcc@1 100.00 ( 98.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][300/391]\tTime  0.486 ( 0.495)\tData  0.000 ( 0.031)\tLoss 3.6773e-02 (4.2068e-02)\tAcc@1  99.22 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][310/391]\tTime  0.496 ( 0.495)\tData  0.000 ( 0.030)\tLoss 2.2270e-02 (4.1991e-02)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][320/391]\tTime  0.488 ( 0.495)\tData  0.000 ( 0.030)\tLoss 1.7349e-02 (4.1895e-02)\tAcc@1 100.00 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][330/391]\tTime  0.486 ( 0.495)\tData  0.000 ( 0.030)\tLoss 2.8564e-02 (4.1723e-02)\tAcc@1  99.22 ( 98.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][340/391]\tTime  0.484 ( 0.494)\tData  0.000 ( 0.030)\tLoss 2.4015e-02 (4.1683e-02)\tAcc@1 100.00 ( 98.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][350/391]\tTime  0.487 ( 0.494)\tData  0.000 ( 0.030)\tLoss 4.5570e-02 (4.1816e-02)\tAcc@1  99.22 ( 98.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][360/391]\tTime  0.490 ( 0.494)\tData  0.000 ( 0.030)\tLoss 5.0255e-02 (4.2106e-02)\tAcc@1  97.66 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][370/391]\tTime  0.492 ( 0.494)\tData  0.000 ( 0.030)\tLoss 5.9357e-02 (4.1995e-02)\tAcc@1  97.66 ( 98.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][380/391]\tTime  0.493 ( 0.494)\tData  0.000 ( 0.030)\tLoss 7.7155e-02 (4.1939e-02)\tAcc@1  98.44 ( 98.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [49][390/391]\tTime  0.435 ( 0.494)\tData  0.000 ( 0.030)\tLoss 4.4741e-02 (4.2060e-02)\tAcc@1  98.75 ( 98.81)\tAcc@5 100.00 (100.00)\n",
            "Test: [  0/100]\tTime  0.672 ( 0.672)\tLoss 2.4012e-01 (2.4012e-01)\tAcc@1  91.00 ( 91.00)\tAcc@5 100.00 (100.00)\n",
            "Test: [ 10/100]\tTime  0.225 ( 0.258)\tLoss 4.3866e-01 (2.6393e-01)\tAcc@1  90.00 ( 92.09)\tAcc@5 100.00 ( 99.82)\n",
            "Test: [ 20/100]\tTime  0.194 ( 0.235)\tLoss 2.7404e-01 (2.7007e-01)\tAcc@1  89.00 ( 91.95)\tAcc@5 100.00 ( 99.71)\n",
            "Test: [ 30/100]\tTime  0.229 ( 0.224)\tLoss 2.7579e-01 (2.8452e-01)\tAcc@1  91.00 ( 91.58)\tAcc@5 100.00 ( 99.68)\n",
            "Test: [ 40/100]\tTime  0.188 ( 0.221)\tLoss 3.7255e-01 (2.9314e-01)\tAcc@1  89.00 ( 91.32)\tAcc@5 100.00 ( 99.61)\n",
            "Test: [ 50/100]\tTime  0.163 ( 0.218)\tLoss 1.9317e-01 (2.9148e-01)\tAcc@1  94.00 ( 91.25)\tAcc@5 100.00 ( 99.59)\n",
            "Test: [ 60/100]\tTime  0.218 ( 0.217)\tLoss 2.8084e-01 (2.9018e-01)\tAcc@1  93.00 ( 91.30)\tAcc@5  99.00 ( 99.64)\n",
            "Test: [ 70/100]\tTime  0.262 ( 0.216)\tLoss 3.7731e-01 (2.8589e-01)\tAcc@1  90.00 ( 91.39)\tAcc@5 100.00 ( 99.68)\n",
            "Test: [ 80/100]\tTime  0.243 ( 0.214)\tLoss 1.9572e-01 (2.8284e-01)\tAcc@1  94.00 ( 91.42)\tAcc@5 100.00 ( 99.67)\n",
            "Test: [ 90/100]\tTime  0.212 ( 0.214)\tLoss 1.9916e-01 (2.8250e-01)\tAcc@1  93.00 ( 91.35)\tAcc@5 100.00 ( 99.68)\n",
            " * Acc@1 91.480 Acc@5 99.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py:299: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
            "  warnings.warn(\"It is recommended that constant folding be turned off ('do_constant_folding=False') \"\n",
            "/usr/local/lib/python3.6/dist-packages/nncf/dynamic_graph/trace_tensor.py:29: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  self.shape = tuple(int(dim) for dim in shape)  # Handle cases when shape is a tuple of Tensors\n",
            "/usr/local/lib/python3.6/dist-packages/nncf/quantization/layers.py:178: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not self.is_enabled_quantization():\n",
            "/usr/local/lib/python3.6/dist-packages/nncf/quantization/layers.py:223: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return self._num_bits.item()\n",
            "/usr/local/lib/python3.6/dist-packages/nncf/quantization/layers.py:381: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return self.signed_tensor.item() == 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhsZ2LmlMDfU"
      },
      "source": [
        "#Accuracy in Pytorch\r\n",
        "\r\n",
        "###Full-presition model: \r\n",
        "\r\n",
        "Acc@1 91.330\r\n",
        "\r\n",
        "### Compressed models:\r\n",
        "\r\n",
        "- int8 quantization: Acc@1 91.480\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX2_CZLw9Rxh"
      },
      "source": [
        "#Export to OpenVINO™ Intermediate Representation (IR)\r\n",
        "To export an ONNX model representation to the OpenVINO IR representation and run it using the Intel® Deep Learning Deployment Toolkit, refer to this [tutorial](https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iexSqiE98hQQ"
      },
      "source": [
        "#Accuracy check using OpenVINO™ Deep Learning accuracy validation framework (Accuracy Checker). \r\n",
        "\r\n",
        "The model was converted to Intermediate Representation (IR) before validation. For more detailes, refer to this [tutorial](https://github.com/openvinotoolkit/open_model_zoo/tree/master/tools/accuracy_checker).\r\n",
        "\r\n",
        "###Full-presition IR model: \r\n",
        "\r\n",
        "Acc@1 91.32\r\n",
        "\r\n",
        "### Compressed IR models:\r\n",
        "\r\n",
        "- int8 quantization: Acc@1 91.49\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpZudmEEFbKN"
      },
      "source": [
        "#Measurement of the performance with OpenVINO™ Benchmark Python* Tool\r\n",
        "\r\n",
        "To compare the performance between the full presition and compressed model refer to this [tutorial](https://github.com/openvinotoolkit/openvino/tree/master/inference-engine/tools/benchmark_tool).\r\n",
        "\r\n",
        "##############################################\r\n",
        "\r\n",
        "### BELOW IS DANGEROUS????????? ###\r\n",
        "\r\n",
        "##############################################\r\n",
        "\r\n",
        "### Set up:\r\n",
        "\r\n",
        "- Hardware: Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz\r\n",
        "\r\n",
        "- Model: Resnet-18\r\n",
        "\r\n",
        "- Input shape: [1, 3, 224, 224]\r\n",
        "\r\n",
        "- Batch size: 1\r\n",
        "\r\n",
        "- Mode: asynchronous\r\n",
        "\r\n",
        "### Results\r\n",
        "\r\n",
        "More than 3x gain in performace after compression of the model:\r\n",
        "\r\n",
        "#### Full-presicion ONNX model:\r\n",
        "- Count:      28902 iterations\r\n",
        "- Duration:   60015.29 ms\r\n",
        "- Latency:    12.43 ms\r\n",
        "- Throughput: 481.58 FPS\r\n",
        "\r\n",
        "#### Compressed ONNX model:\r\n",
        "\r\n",
        "##### int8 quantization:\r\n",
        "\r\n",
        "- Count:      94014 iterations\r\n",
        "- Duration:   60005.72 ms\r\n",
        "- Latency:    3.81 ms\r\n",
        "- Throughput: 1566.75 FPS\r\n"
      ]
    }
  ]
}